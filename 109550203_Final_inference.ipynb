{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from joblib import load\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from joblib import dump\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTestData = pd.read_csv(\"test.csv\")\n",
    "xTestData = xTestData.reset_index().set_index('id').drop('index', axis=1)\n",
    "\n",
    "selectionOfFeatures = ['area', 'missingm5', 'missingm3', 'measurement_17', 'measurement_2', 'measurement_1', 'measurement_0', 'loading']\n",
    "\n",
    "xTestData['missingm3'] = xTestData.measurement_3.isna()\n",
    "xTestData['missingm5'] = xTestData.measurement_5.isna()\n",
    "\n",
    "testFeatures = []\n",
    "for values in xTestData.columns:\n",
    "    if values == 'loading' or (values.startswith('measurement') and values != 'measurement_17'):\n",
    "        testFeatures.append(values)\n",
    "chosenImputer = KNNImputer(missing_values=np.nan, n_neighbors=15)\n",
    "chosenImputer.fit(xTestData[testFeatures])\n",
    "xTestData[testFeatures] = chosenImputer.transform(xTestData[testFeatures])\n",
    "\n",
    "###\n",
    "# float_features = []\n",
    "# for feature in xTestData.columns:\n",
    "#     if xTestData[feature].dtypes == 'float64':\n",
    "#         float_features.append(feature)\n",
    "\n",
    "# standardAverage = []\n",
    "# for feature in float_features:\n",
    "#     if feature != 'loading':\n",
    "#         standardAverage.append(feature)\n",
    "        \n",
    "# xTestData['measurement3to17Average'] = xTestData[standardAverage].mean(axis=1)\n",
    "# xTestData['measurement3to17stdev'] = xTestData[standardAverage].std(axis=1)\n",
    "###\n",
    "\n",
    "comparableColumns = ['measurement_3', 'measurement_4', 'measurement_5','measurement_6', 'measurement_7', 'measurement_8', 'measurement_9']\n",
    "xTestData['measurement17predictions'] = \"\"\n",
    "test_list = ['F', 'G', 'H', 'I']\n",
    "for result in test_list:\n",
    "    train_source = xTestData[(xTestData['product_code'] == result) & ~pd.isnull(xTestData.measurement_17)]\n",
    "    LRofMeasurement17 = LinearRegression().fit(train_source[comparableColumns], train_source['measurement_17'])\n",
    "    sourceForPrediction = xTestData[xTestData['product_code'] == result]\n",
    "    xTestData.loc[sourceForPrediction.index, 'measurement17predictions'] = LRofMeasurement17.predict(sourceForPrediction[comparableColumns])\n",
    "    xTestData.loc[sourceForPrediction[pd.isnull(sourceForPrediction.measurement_17)].index, 'measurement_17'] = xTestData.loc[sourceForPrediction[pd.isnull(sourceForPrediction.measurement_17)].index, 'measurement17predictions']\n",
    "    \n",
    "PCAObjectives = [\n",
    "    'measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7',\n",
    "    'measurement_8', 'measurement_9', 'measurement_10', 'measurement_11', 'measurement_12',\n",
    "    'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16'\n",
    "]\n",
    "\n",
    "pcaApplied = PCA(n_components=1)\n",
    "xTestData['pcaApplied'] = pcaApplied.fit_transform(xTestData[PCAObjectives])\n",
    "\n",
    "xTestData['measurement_2'] = xTestData['measurement_2'].clip(11, None)\n",
    "\n",
    "xTestData['area'] = xTestData['attribute_2'] * xTestData['attribute_3']\n",
    "\n",
    "dropped = ['measurement_3', 'measurement_4', 'measurement_5', 'measurement_6', 'measurement_7',\n",
    "            'measurement_8', 'measurement_9', 'measurement_10', 'measurement_11', 'measurement_12',\n",
    "            'measurement_13', 'measurement_14', 'measurement_15', 'measurement_16']\n",
    "xTestData = xTestData.drop(dropped, axis=1)\n",
    "dropped2 = ['product_code', 'attribute_3', 'attribute_2', 'attribute_1', 'attribute_0']\n",
    "xTestData = xTestData.drop(dropped2, axis=1)\n",
    "xTestData[selectionOfFeatures] = StandardScaler().fit_transform(xTestData[selectionOfFeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='l1', C=0.01, solver='liblinear', random_state=1)\n",
    "model = load('predictions.joblib') \n",
    "y_pred = model.predict_proba(xTestData)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('sample_submission.csv', index_col='id')\n",
    "sample['id'] = xTestData.index\n",
    "sample['failure'] =  y_pred\n",
    "sample.to_csv(\"109550203.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25034407fed5d681614dac11a1c0537e8cb49e3a8883c071303eea01322943d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
